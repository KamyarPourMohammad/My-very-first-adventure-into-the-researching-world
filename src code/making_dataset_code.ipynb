{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2169393,"sourceType":"datasetVersion","datasetId":1302315}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchxrayvision==1.2.1 torchvision\n!pip install torch\n!pip install scikit-learn\n!pip install tqdm\n!pip install pandas\n!pip install grad-cam\n# ۱. نصب نسخه‌هایی که با هم سازگار هستند\n!pip install --upgrade \"numpy<1.24.0\" \"scipy<1.14.0\"\n\n# ۲. ریستارت کردن محیط (اجباری)\n# بعد از اجرای کد بالا، از منوی بالای صفحه Kaggle گزینه:\n# Run -> Restart Session\n# رو بزن تا تغییرات اعمال بشه.","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.listdir(\"/kaggle/input/chexpert\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:06:55.568227Z","iopub.execute_input":"2025-12-28T11:06:55.568927Z","iopub.status.idle":"2025-12-28T11:06:55.586277Z","shell.execute_reply.started":"2025-12-28T11:06:55.568887Z","shell.execute_reply":"2025-12-28T11:06:55.585300Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"['valid.csv', 'valid', 'train.csv', 'train']"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"# اول اگر لینک یا پوشه‌ای با این اسم هست رو پاک کن\n!rm -rf /kaggle/working/CheXpert-v1.0-small\n\n# حالا دوباره لینک رو بساز\n!ln -s /kaggle/input/chexpert /kaggle/working/CheXpert-v1.0-small","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:00.965138Z","iopub.execute_input":"2025-12-28T11:07:00.965492Z","iopub.status.idle":"2025-12-28T11:07:01.196973Z","shell.execute_reply.started":"2025-12-28T11:07:00.965463Z","shell.execute_reply":"2025-12-28T11:07:01.196006Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom sklearn.metrics import roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:04.596817Z","iopub.execute_input":"2025-12-28T11:07:04.597119Z","iopub.status.idle":"2025-12-28T11:07:12.140627Z","shell.execute_reply.started":"2025-12-28T11:07:04.597096Z","shell.execute_reply":"2025-12-28T11:07:12.139934Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\nfrom PIL import Image\n\nCHEXPERT14 = [\n    \"Enlarged Cardiomediastinum\", \"Cardiomegaly\", \"Lung Opacity\",\n    \"Lung Lesion\", \"Edema\", \"Consolidation\", \"Atelectasis\",\n    \"Pneumothorax\", \"Pleural Effusion\", \"Support Devices\"\n]\n\nclass CheXpertDataset(Dataset):\n    def __init__(self, csv_path, img_dir, transform=None):\n        self.df = pd.read_csv(csv_path)\n        self.img_dir = img_dir\n        self.transform = transform\n\n        if \"Path\" not in self.df.columns and \"path\" in self.df.columns:\n            self.df.rename(columns={\"path\": \"Path\"}, inplace=True)\n\n        drop_cols = [\"Sex\", \"Age\", \"Frontal/Lateral\", \"AP/PA\", \"View\", \"Unnamed: 0\"]\n        self.df = self.df.drop(columns=[c for c in drop_cols if c in self.df.columns], errors=\"ignore\")\n\n        present_labels = [c for c in CHEXPERT14 if c in self.df.columns]\n        self.df = self.df[[\"Path\"] + present_labels].copy()\n        self.label_cols = present_labels\n\n        for c in self.label_cols:\n            self.df[c] = pd.to_numeric(self.df[c], errors=\"coerce\")  # 非法转成 NaN\n            self.df[c] = self.df[c].replace(-1, 0)                   # -1 -> 0\n            self.df[c] = self.df[c].fillna(0).astype(np.float32)     # NaN -> 0, 并转 float32\n\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row[\"Path\"].lstrip(\"/\"))\n\n        if not os.path.exists(img_path):\n            raise FileNotFoundError(f\"File not found: {img_path}\")\n\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n\n        labels_np = row[self.label_cols].to_numpy(dtype=np.float32, copy=True)\n        labels = torch.from_numpy(labels_np)  # dtype=float32\n        return image, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:15.746614Z","iopub.execute_input":"2025-12-28T11:07:15.747526Z","iopub.status.idle":"2025-12-28T11:07:15.757024Z","shell.execute_reply.started":"2025-12-28T11:07:15.747498Z","shell.execute_reply":"2025-12-28T11:07:15.756251Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from torchvision import transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\ntrain_dataset = CheXpertDataset(\n    csv_path=\"/kaggle/input/chexpert/train.csv\",\n    img_dir=\"/kaggle/working\",\n    transform=train_transform\n)\nval_dataset = CheXpertDataset(\n    csv_path=\"/kaggle/input/chexpert/valid.csv\",\n    img_dir=\"/kaggle/working\",\n    transform=val_transform\n)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:25.696724Z","iopub.execute_input":"2025-12-28T11:07:25.697044Z","iopub.status.idle":"2025-12-28T11:07:26.411866Z","shell.execute_reply.started":"2025-12-28T11:07:25.697023Z","shell.execute_reply":"2025-12-28T11:07:26.411160Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ۱. مدل رو تعریف کن\nmodel = models.densenet121(pretrained=False) # یا هر مدلی که ساختی\nnum_ftrs = model.classifier.in_features\nmodel.classifier = nn.Linear(num_ftrs, 10) # چون ۱۰ تا لیبل داری\n\n# آدرسی که کپی کردی رو دقیقاً اینجا بذار\ncheckpoint_path = '/kaggle/input/my-classification-model2/pytorch/default/1/best_densenet_chexpert.pt'\n\n# لود کردن وزن‌ها\nmodel.load_state_dict(torch.load(checkpoint_path, map_location=device))\nmodel.to(device)\nmodel.eval()\n\nprint(\"وزن‌ها با موفقیت از بخش Input لود شدند!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:41.934942Z","iopub.execute_input":"2025-12-28T11:07:41.935601Z","iopub.status.idle":"2025-12-28T11:07:42.992839Z","shell.execute_reply.started":"2025-12-28T11:07:41.935577Z","shell.execute_reply":"2025-12-28T11:07:42.991889Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"وزن‌ها با موفقیت از بخش Input لود شدند!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, shutil\n\nos.makedirs(\"/kaggle/outputs\", exist_ok=True)\n\nfor file in os.listdir(\"/kaggle/working\"):\n    if file.endswith(\".pt\"):\n        src = os.path.join(\"/kaggle/working\", file)\n        dst = os.path.join(\"/kaggle/outputs\", file)\n        shutil.copy(src, dst)\n        print(f\"{file}\")\n\nprint(\"\\n All models have been successfully copied to /kaggle/outputs. You can download them from the Output → Files page.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:07:48.125335Z","iopub.execute_input":"2025-12-28T11:07:48.125673Z","iopub.status.idle":"2025-12-28T11:07:48.131978Z","shell.execute_reply.started":"2025-12-28T11:07:48.125650Z","shell.execute_reply":"2025-12-28T11:07:48.131188Z"}},"outputs":[{"name":"stdout","text":"\n All models have been successfully copied to /kaggle/outputs. You can download them from the Output → Files page.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import os\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom pytorch_grad_cam import GradCAM\n\n# ۱. تنظیمات پوشه‌ها\nbase_path = '/kaggle/working/CheXpert-v1.0-small'\noutput_folder = '/kaggle/working/my_custom_dataset'\nmasks_path = os.path.join(output_folder, 'masks')\nos.makedirs(masks_path, exist_ok=True)\n\nprint(\"در حال جستجوی سریع برای پیدا کردن ۱۰۰۰ عکس...\", flush=True)\n\n# ۲. پیدا کردن سریع ۱۰۰۰ عکس (بدون اسکن کردن کل دایرکتوری)\nall_image_info = []\nfound_count = 0\nfor root, _, files in os.walk(base_path):\n    for file in files:\n        if file.endswith(\".jpg\"):\n            full_path = os.path.join(root, file)\n            rel_path = os.path.relpath(full_path, base_path)\n            all_image_info.append((full_path, rel_path))\n            found_count += 1\n        if found_count >= 1000: break # به محض رسیدن به ۱۰۰۰ تا استاپ کن\n    if found_count >= 1000: break\n\nprint(f\"یافت شد! شروع تولید ماسک برای {len(all_image_info)} عکس...\", flush=True)\n\n# ۳. تنظیم Grad-CAM\ntarget_layers = [model.features.norm5]\ncam = GradCAM(model=model, target_layers=target_layers)\n\ndataset_records = []\n\n# ۴. حلقه تولید با tqdm\nfor img_path, rel_path in tqdm(all_image_info):\n    try:\n        rgb_img = cv2.imread(img_path)\n        if rgb_img is None: continue\n        \n        rgb_img_resized = cv2.resize(rgb_img, (224, 224))\n        img_tensor = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n        ])(rgb_img_resized).unsqueeze(0).to(device)\n\n        # تولید ماسک\n        mask = cam(input_tensor=img_tensor, targets=None)[0, :]\n        mask_uint8 = (mask * 255).astype(np.uint8)\n\n        # نام‌گذاری و ذخیره\n        mask_filename = rel_path.replace(os.sep, '_') \n        mask_save_path = os.path.join(masks_path, mask_filename)\n        cv2.imwrite(mask_save_path, mask_uint8)\n\n        dataset_records.append({\n            'original_image_path': img_path,\n            'mask_path': mask_save_path\n        })\n    except Exception as e:\n        continue\n\n# ۵. ذخیره فایل CSV\ndf = pd.DataFrame(dataset_records)\ndf.to_csv(os.path.join(output_folder, 'dataset_info.csv'), index=False)\n\nprint(f\"\\nتموم شد! دیتاست در {output_folder} آماده استفاده است.\", flush=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T11:24:58.725534Z","iopub.execute_input":"2025-12-28T11:24:58.725854Z","iopub.status.idle":"2025-12-28T11:26:39.096838Z","shell.execute_reply.started":"2025-12-28T11:24:58.725832Z","shell.execute_reply":"2025-12-28T11:26:39.096125Z"}},"outputs":[{"name":"stdout","text":"در حال جستجوی سریع برای پیدا کردن ۱۰۰۰ عکس...\nیافت شد! شروع تولید ماسک برای 1000 عکس...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1000/1000 [01:09<00:00, 14.35it/s]","output_type":"stream"},{"name":"stdout","text":"\nتموم شد! دیتاست در /kaggle/working/my_custom_dataset آماده استفاده است.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!ls -lh /kaggle/outputs","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\n\nckpt_path = \"best_densenet_chexpert.pt\"  \nstate = torch.load(ckpt_path, map_location=device)\nmodel.load_state_dict(state)\nmodel.to(device)\nmodel.eval()\n\nval_loss = 0.0\npreds_all, labels_all = [], []\n\nwith torch.no_grad():\n    for imgs, labels in tqdm(val_loader, desc=\"Validation\"):\n        imgs = imgs.to(device)\n        labels = labels.to(device)\n\n        logits = model(imgs)                      \n        loss = criterion(logits, labels)         \n        val_loss += loss.item()\n\n        probs = torch.sigmoid(logits).cpu().numpy()   \n        preds_all.append(probs)\n        labels_all.append(labels.cpu().numpy())\n\navg_val_loss = val_loss / len(val_loader)\npreds_all = np.concatenate(preds_all, axis=0)   # [N, C]\nlabels_all = np.concatenate(labels_all, axis=0) # [N, C]\n\nvalid_aucs = []\nskipped = []\n\nnum_classes = labels_all.shape[1]\nfor i in range(num_classes):\n    y_true = labels_all[:, i]\n    y_pred = preds_all[:, i]\n    if len(np.unique(y_true)) < 2:\n        skipped.append(i)\n        continue\n    auc_i = roc_auc_score(y_true, y_pred)\n    valid_aucs.append(auc_i)\n\nval_auc = np.mean(valid_aucs) if len(valid_aucs) > 0 else np.nan\n\nprint(\"========== Validation Summary ==========\")\nprint(f\"Loss: {avg_val_loss:.4f}\")\nprint(f\"Macro AUC (valid cols): {val_auc:.4f}\" if not np.isnan(val_auc) else \"Macro AUC: NaN\")\nif skipped:\n    print(f\"Skipped label indices (no 0/1 mix in val): {skipped}\")\nprint(f\"Used {len(valid_aucs)}/{num_classes} labels for AUC.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"label_names = train_dataset.label_cols   # the 10 CheXLocalize labels\n\nper_label_auc = {}\n\nfor i, label in enumerate(label_names):\n    y_true = labels_all[:, i]\n    y_pred = preds_all[:, i]\n\n    # Skip labels with only one class in validation (all 0 or all 1)\n    if len(np.unique(y_true)) < 2:\n        per_label_auc[label] = \"N/A (only one class present)\"\n        continue\n\n    auc_i = roc_auc_score(y_true, y_pred)\n    per_label_auc[label] = auc_i\n\nprint(\"\\n========== PER-LABEL AUC ==========\\n\")\nfor label, auc in per_label_auc.items():\n    print(f\"{label:30} : {auc}\")\n\n# Mean AUC over valid labels\nvalid_aucs = [v for v in per_label_auc.values() if isinstance(v, float)]\nprint(\"\\nMacro AUC:\", np.mean(valid_aucs))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}